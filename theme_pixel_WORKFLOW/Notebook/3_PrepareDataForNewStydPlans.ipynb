{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssH3SIKtuSQA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('Curriculum_Data Science_22-23.xlsx')\n",
        "data"
      ],
      "metadata": {
        "id": "RoTUqqIqulBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_competances=pd.read_csv('Competances.csv')\n",
        "data_competances\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "_RdzGWPE9Wtx",
        "outputId": "be1abd84-17fc-4f9a-d378-05d90335b81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  Topic                        Name  \\\n",
              "0             0             0           0     -1               tronc commun    \n",
              "1             1             1           1      0       Business Intelligence   \n",
              "2             2             2           2      1        Software Engineering   \n",
              "3             3             3           4      3                Data Science   \n",
              "4             4             4           5      4             Cloud Computing   \n",
              "5             5             5           8      7  Full Stack Web Development   \n",
              "\n",
              "                                           Prerequis  \\\n",
              "0                                                NaN   \n",
              "1  [\"['Microsoft Power BI', 'Spring Boot', 'Busin...   \n",
              "2  ['JavaScript', 'unknown', 'MySQL', 'Java', 'Py...   \n",
              "3  ['Machine Learning', 'Python', 'Big Data', 'De...   \n",
              "4  [\"['unknown', 'Linux', 'Gitlab', 'Continuous I...   \n",
              "5  ['Data analysis', 'Microsoft Power BI', 'Big D...   \n",
              "\n",
              "                                          Competency  \\\n",
              "0  ['big data', 'shell scripting', 'project engin...   \n",
              "1  ['data analysis', 'database design', 'CRM', 'm...   \n",
              "2  ['asp net', 'software design', 'mongodb', 'c #...   \n",
              "3  ['web scraping', 'data analysis', 'Computer vi...   \n",
              "4  ['web development', 'deployments services', 'g...   \n",
              "5  ['data mining', 'gitlab', 'pl sql', 'sql serve...   \n",
              "\n",
              "                                            outcomes  \\\n",
              "0  ['Some potential outcomes of using big data ar...   \n",
              "1  ['The outcomes of using data analysis can vary...   \n",
              "2  ['Some potential outcomes of using ASP.NET inc...   \n",
              "3  ['The outcomes of using web scraping can depen...   \n",
              "4  ['The outcomes of using web development can va...   \n",
              "5  ['The outcomes of data mining can be divided i...   \n",
              "\n",
              "                                            Duration  \n",
              "0  [14.593619346618652, 14.774022102355957, 15.46...  \n",
              "1  [12.411352157592773, 12.041346549987793, 12.56...  \n",
              "2  [18.319828033447266, 15.108773231506348, 18.36...  \n",
              "3  [9.884196281433105, 9.681196212768555, 9.59127...  \n",
              "4  [10.460183143615723, 12.573527336120605, 12.87...  \n",
              "5  [12.789751052856445, 15.370535850524902, 11.94...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1b13344-1d06-4baa-b2af-8942b63923ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Name</th>\n",
              "      <th>Prerequis</th>\n",
              "      <th>Competency</th>\n",
              "      <th>outcomes</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>tronc commun</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['big data', 'shell scripting', 'project engin...</td>\n",
              "      <td>['Some potential outcomes of using big data ar...</td>\n",
              "      <td>[14.593619346618652, 14.774022102355957, 15.46...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Business Intelligence</td>\n",
              "      <td>[\"['Microsoft Power BI', 'Spring Boot', 'Busin...</td>\n",
              "      <td>['data analysis', 'database design', 'CRM', 'm...</td>\n",
              "      <td>['The outcomes of using data analysis can vary...</td>\n",
              "      <td>[12.411352157592773, 12.041346549987793, 12.56...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Software Engineering</td>\n",
              "      <td>['JavaScript', 'unknown', 'MySQL', 'Java', 'Py...</td>\n",
              "      <td>['asp net', 'software design', 'mongodb', 'c #...</td>\n",
              "      <td>['Some potential outcomes of using ASP.NET inc...</td>\n",
              "      <td>[18.319828033447266, 15.108773231506348, 18.36...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>Data Science</td>\n",
              "      <td>['Machine Learning', 'Python', 'Big Data', 'De...</td>\n",
              "      <td>['web scraping', 'data analysis', 'Computer vi...</td>\n",
              "      <td>['The outcomes of using web scraping can depen...</td>\n",
              "      <td>[9.884196281433105, 9.681196212768555, 9.59127...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Cloud Computing</td>\n",
              "      <td>[\"['unknown', 'Linux', 'Gitlab', 'Continuous I...</td>\n",
              "      <td>['web development', 'deployments services', 'g...</td>\n",
              "      <td>['The outcomes of using web development can va...</td>\n",
              "      <td>[10.460183143615723, 12.573527336120605, 12.87...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>Full Stack Web Development</td>\n",
              "      <td>['Data analysis', 'Microsoft Power BI', 'Big D...</td>\n",
              "      <td>['data mining', 'gitlab', 'pl sql', 'sql serve...</td>\n",
              "      <td>['The outcomes of data mining can be divided i...</td>\n",
              "      <td>[12.789751052856445, 15.370535850524902, 11.94...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1b13344-1d06-4baa-b2af-8942b63923ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1b13344-1d06-4baa-b2af-8942b63923ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1b13344-1d06-4baa-b2af-8942b63923ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##s=data['Unnamed: 1']\n",
        "listaa = data_competances[data_competances.Topic==-1].Duration\n"
      ],
      "metadata": {
        "id": "i0bgagtAwY1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listaa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrUT0RH00s-D",
        "outputId": "116893aa-5c0a-4aed-a5f3-d19a79c579fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [14.593619346618652, 14.774022102355957, 15.46...\n",
              "Name: Duration, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "listq=[]\n",
        "for e in listaa : \n",
        "  e=eval(e)\n",
        "  listq.append(e)"
      ],
      "metadata": {
        "id": "rh7a_pWj0_ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "flat_list2 = list(itertools.chain.from_iterable(listq))\n"
      ],
      "metadata": {
        "id": "4nZqo3DF8p5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_list1=flat_list1[:-1]"
      ],
      "metadata": {
        "id": "AyuVgmVp8xjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Created new dataframes from comptency data composed by 2 columns competency and duration, this process will wa repeated with all the specialties \n",
        "df_commun = pd.DataFrame({'Comptency': flat_list1, 'Duration 2': flat_list2})\n"
      ],
      "metadata": {
        "id": "LBf7pvS87-AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_commun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "RVWrEXeqB1LF",
        "outputId": "478adc78-7137-4b02-a4bb-7bda8afafff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Comptency  Duration 2\n",
              "0                  big data   14.593619\n",
              "1           shell scripting   14.774022\n",
              "2       project engineering   15.461201\n",
              "3        project management   14.062950\n",
              "4           microsoft azure   14.455705\n",
              "5           test automation   14.736641\n",
              "6                       OOP   11.668024\n",
              "7                     linux   11.996387\n",
              "8                    french   12.175062\n",
              "9                   english   17.797428\n",
              "10     deployments services   18.062803\n",
              "11                  asp net   14.264272\n",
              "12  database administration   11.636148\n",
              "13               algorithms   14.969799\n",
              "14       spring integration   14.953724\n",
              "15   network administration   12.081783\n",
              "16            communication   14.550884\n",
              "17  relationship management   14.539782\n",
              "18     process optimization   11.955803\n",
              "19                    agile   15.011433\n",
              "20                   devops   14.546086\n",
              "21             web services   14.959303\n",
              "22          problem solving   21.428572\n",
              "23             microservice   14.620686\n",
              "24       management control   14.713964\n",
              "25    system administration   14.978388\n",
              "26              spring boot   15.186634\n",
              "27                     jira   14.732976\n",
              "28               unit tests   14.998128"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a2d7cc6-d6a3-4b2c-b1d8-1970fc3c2588\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comptency</th>\n",
              "      <th>Duration 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>big data</td>\n",
              "      <td>14.593619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>shell scripting</td>\n",
              "      <td>14.774022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>project engineering</td>\n",
              "      <td>15.461201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>project management</td>\n",
              "      <td>14.062950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>microsoft azure</td>\n",
              "      <td>14.455705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>test automation</td>\n",
              "      <td>14.736641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OOP</td>\n",
              "      <td>11.668024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>linux</td>\n",
              "      <td>11.996387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>french</td>\n",
              "      <td>12.175062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>english</td>\n",
              "      <td>17.797428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>deployments services</td>\n",
              "      <td>18.062803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>asp net</td>\n",
              "      <td>14.264272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>database administration</td>\n",
              "      <td>11.636148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>algorithms</td>\n",
              "      <td>14.969799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>spring integration</td>\n",
              "      <td>14.953724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>network administration</td>\n",
              "      <td>12.081783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>communication</td>\n",
              "      <td>14.550884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>relationship management</td>\n",
              "      <td>14.539782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>process optimization</td>\n",
              "      <td>11.955803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>agile</td>\n",
              "      <td>15.011433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>devops</td>\n",
              "      <td>14.546086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>web services</td>\n",
              "      <td>14.959303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>problem solving</td>\n",
              "      <td>21.428572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>microservice</td>\n",
              "      <td>14.620686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>management control</td>\n",
              "      <td>14.713964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>system administration</td>\n",
              "      <td>14.978388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>spring boot</td>\n",
              "      <td>15.186634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>jira</td>\n",
              "      <td>14.732976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>unit tests</td>\n",
              "      <td>14.998128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a2d7cc6-d6a3-4b2c-b1d8-1970fc3c2588')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a2d7cc6-d6a3-4b2c-b1d8-1970fc3c2588 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a2d7cc6-d6a3-4b2c-b1d8-1970fc3c2588');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Same For all specialities (all the CSVs will be used to created the new study plans)\n",
        "df_commun.to_csv('Tronc_Commun.csv', index=False)\n"
      ],
      "metadata": {
        "id": "HXlt2496AIqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Simple test fo similarity all the next cells are for the same purpose test similraty between list from the old stydy plan and data extracted from our new source comptency \n",
        "list_tronc_commun = [\n",
        "  \"Communication, Culture and Citizenship F4\",\n",
        "                  \"Intellectual Property Law\",\n",
        "       \"Information Systems (IS) Architecture I\",\n",
        "                       \"Graphs and applications\",\n",
        "                             \"Linear Programming\",\n",
        "     \"Complexity applied to Operations Research \",\n",
        "                        \"Database Administration\",\n",
        "            \"Service and Network Administration\",\n",
        "             \"English For Engineers\",\n",
        "                \"Advanced Operating System\",\n",
        "                             \"Computer Security\",                                \n",
        "                       \"Web Services\",\n",
        "    \"Information Systems (IS) Architecture II\",\n",
        "                            \"Project Management\",\n",
        "              \"Innovation and Entrepreneurship\"  ]\n",
        "list_specialite=[\"Probability\",\"Statistics\", \"Machine Learning\", \"Big Data Analytics\", \"Times Series \",\"Python Framework for the Web\",\"Deep Learning\", \"Data Science Project\" ]"
      ],
      "metadata": {
        "id": "a_3t-mf4izzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_md\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1W0-akMh-NS",
        "outputId": "93a594ba-b86f-41ef-b9e2-d15914f5d4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "2023-05-12 15:16:51.057747: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 15:16:52.303849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvhEAj1KiclM",
        "outputId": "8fa18128-54a7-45ca-ecf0-242c37059a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Simple test fo similarity \n",
        "import spacy\n",
        "# Load the large English NLP model from spaCy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "nlp.enable_pipe(\"senter\")\n",
        "\n",
        "# Define two example technologies to compare\n",
        "##tech1 = \"Python\"\n",
        "##tech2 = \"Data analysis\"\n",
        "# Print the similarity score between the two technologies\n",
        "##print(\"Similarity score between\", tech1, \"and\", tech2, \":\", similarity_score)\n",
        "def similarity(tech1, tech2):\n",
        "\n",
        "# Calculate the semantic similarity between the two technologies\n",
        "    doc1 = nlp(tech1)\n",
        "    doc2 = nlp(tech2)\n",
        "    similarity_score = doc1.similarity(doc2)\n",
        "    return similarity_score\n",
        "\n",
        "list1 = list_specialite\n",
        "##list2 = listaa\n",
        "for i in list1 :\n",
        "  for j in listq :\n",
        "    for k in j :\n",
        "      if (similarity(i,k)<0.4):\n",
        "      ##similarity = similarity(i,k)\n",
        "         print(f\"Similarity between {i} and {k} is {similarity(i,k)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Vr6Oan1I9Y9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a93d04-b9e4-47dc-9053-002af8ef2a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between Probability and web scraping is 0.28181155857982837\n",
            "Similarity between Probability and Natural language processing (NLP) is 0.33630915191726424\n",
            "Similarity between Probability and python is 0.13880068600072873\n",
            "Similarity between Probability and matlab is 0.14798678296949283\n",
            "Similarity between Probability and flask is 0.06799424357047895\n",
            "Similarity between Probability and django is -0.02513048684382098\n",
            "Similarity between Probability and R is 0.19083508556655343\n",
            "Similarity between Probability and chatbot is 0.07724508888100937\n",
            "Similarity between Statistics and web scraping is 0.1638399871188612\n",
            "Similarity between Statistics and linear algebra is 0.21798937773309326\n",
            "Similarity between Statistics and machine learning is 0.2847310603137827\n",
            "Similarity between Statistics and Natural language processing (NLP) is 0.3983998353420952\n",
            "Similarity between Statistics and python is 0.12436203227035868\n",
            "Similarity between Statistics and matlab is 0.14260019577809135\n",
            "Similarity between Statistics and deep learning is 0.18989312625027352\n",
            "Similarity between Statistics and flask is -0.1058448406756634\n",
            "Similarity between Statistics and django is 0.04685456660942316\n",
            "Similarity between Statistics and big data is 0.31036109846304\n",
            "Similarity between Statistics and R is 0.1335854455471389\n",
            "Similarity between Statistics and chatbot is 0.05465505554289465\n",
            "Similarity between Statistics and time series is 0.2360425423833347\n",
            "Similarity between Machine Learning and web scraping is 0.2554847989809421\n",
            "Similarity between Machine Learning and data analysis is 0.39245725340296517\n",
            "Similarity between Machine Learning and linear algebra is 0.2699559205066212\n",
            "Similarity between Machine Learning and probability is 0.34167839847578785\n",
            "Similarity between Machine Learning and python is 0.21526704568360408\n",
            "Similarity between Machine Learning and matlab is 0.18412574397570178\n",
            "Similarity between Machine Learning and flask is -0.028866198164574305\n",
            "Similarity between Machine Learning and django is 0.13279652764049332\n",
            "Similarity between Machine Learning and big data is 0.16471483080775945\n",
            "Similarity between Machine Learning and R is 0.2135284253205567\n",
            "Similarity between Machine Learning and chatbot is 0.19922418211861764\n",
            "Similarity between Machine Learning and time series is 0.30550287084475325\n",
            "Similarity between Big Data Analytics and web scraping is 0.2069433334623946\n",
            "Similarity between Big Data Analytics and linear algebra is 0.13943958150683594\n",
            "Similarity between Big Data Analytics and probability is 0.13220287621046534\n",
            "Similarity between Big Data Analytics and machine learning is 0.18302467755713764\n",
            "Similarity between Big Data Analytics and Natural language processing (NLP) is 0.2992903530125379\n",
            "Similarity between Big Data Analytics and Deep learning language model is 0.3439308734846842\n",
            "Similarity between Big Data Analytics and python is 0.2026240101271464\n",
            "Similarity between Big Data Analytics and matlab is 0.20588665685171176\n",
            "Similarity between Big Data Analytics and deep learning is 0.11416582096003336\n",
            "Similarity between Big Data Analytics and flask is -0.023728935703392705\n",
            "Similarity between Big Data Analytics and django is 0.17962616177627413\n",
            "Similarity between Big Data Analytics and R is 0.1344843483937692\n",
            "Similarity between Big Data Analytics and chatbot is 0.21823116953031205\n",
            "Similarity between Big Data Analytics and time series is 0.15466698196664153\n",
            "Similarity between Big Data Analytics and artificial intelligence is 0.24788906588419302\n",
            "Similarity between Times Series  and web scraping is 0.042706834387146\n",
            "Similarity between Times Series  and data analysis is 0.16852962172299485\n",
            "Similarity between Times Series  and Computer vision is 0.3274531864807503\n",
            "Similarity between Times Series  and Statistics is 0.3518791402226166\n",
            "Similarity between Times Series  and linear algebra is 0.1120691331426002\n",
            "Similarity between Times Series  and probability is 0.1180750414201754\n",
            "Similarity between Times Series  and machine learning is 0.09126218835851933\n",
            "Similarity between Times Series  and Natural language processing (NLP) is 0.23904627522588745\n",
            "Similarity between Times Series  and Deep learning language model is 0.2698472212731264\n",
            "Similarity between Times Series  and python is -0.05638787058737973\n",
            "Similarity between Times Series  and matlab is -0.059972816290042336\n",
            "Similarity between Times Series  and deep learning is 0.030602032079393215\n",
            "Similarity between Times Series  and data visualization is 0.16610856282047695\n",
            "Similarity between Times Series  and flask is -0.12028235339972691\n",
            "Similarity between Times Series  and django is -0.02869506730007042\n",
            "Similarity between Times Series  and big data is 0.019571973576084575\n",
            "Similarity between Times Series  and data integration is 0.1812588329660593\n",
            "Similarity between Times Series  and R is 0.22098650313066626\n",
            "Similarity between Times Series  and chatbot is -0.030537833779576147\n",
            "Similarity between Times Series  and time series is 0.39623074115233514\n",
            "Similarity between Times Series  and artificial intelligence is 0.1912645907925567\n",
            "Similarity between Python Framework for the Web and linear algebra is 0.37763641793430364\n",
            "Similarity between Python Framework for the Web and Natural language processing (NLP) is 0.3174132259820214\n",
            "Similarity between Python Framework for the Web and python is 0.38746140964131465\n",
            "Similarity between Python Framework for the Web and matlab is 0.3047855696354557\n",
            "Similarity between Python Framework for the Web and deep learning is 0.3999129997147227\n",
            "Similarity between Python Framework for the Web and flask is 0.024920275095937628\n",
            "Similarity between Python Framework for the Web and django is 0.2859430762411603\n",
            "Similarity between Python Framework for the Web and big data is 0.3848476126927111\n",
            "Similarity between Python Framework for the Web and R is 0.09428967056066134\n",
            "Similarity between Python Framework for the Web and chatbot is 0.3050328766201963\n",
            "Similarity between Deep Learning and web scraping is 0.18377632491638\n",
            "Similarity between Deep Learning and data analysis is 0.31672356799251483\n",
            "Similarity between Deep Learning and Statistics is 0.36511628626710435\n",
            "Similarity between Deep Learning and linear algebra is 0.19412911359614676\n",
            "Similarity between Deep Learning and probability is 0.21507630509629438\n",
            "Similarity between Deep Learning and Natural language processing (NLP) is 0.37384989623443216\n",
            "Similarity between Deep Learning and python is 0.19650305465220133\n",
            "Similarity between Deep Learning and matlab is 0.1490745515970595\n",
            "Similarity between Deep Learning and data visualization is 0.3610271267110699\n",
            "Similarity between Deep Learning and flask is -0.045399635217749056\n",
            "Similarity between Deep Learning and django is 0.14487061819469588\n",
            "Similarity between Deep Learning and big data is 0.15244958892497043\n",
            "Similarity between Deep Learning and data integration is 0.36997903156184586\n",
            "Similarity between Deep Learning and R is 0.13351666857619435\n",
            "Similarity between Deep Learning and chatbot is 0.10931905786644314\n",
            "Similarity between Deep Learning and time series is 0.24216153172363797\n",
            "Similarity between Deep Learning and artificial intelligence is 0.37359692756803836\n",
            "Similarity between Data Science Project and web scraping is 0.18845787455403737\n",
            "Similarity between Data Science Project and linear algebra is 0.14272035388839316\n",
            "Similarity between Data Science Project and probability is 0.29227826944934177\n",
            "Similarity between Data Science Project and machine learning is 0.2915647819426775\n",
            "Similarity between Data Science Project and python is 0.17965252504315765\n",
            "Similarity between Data Science Project and matlab is 0.16085891270295308\n",
            "Similarity between Data Science Project and deep learning is 0.19466859804700098\n",
            "Similarity between Data Science Project and flask is -0.04606955265721491\n",
            "Similarity between Data Science Project and django is 0.09616913395880865\n",
            "Similarity between Data Science Project and big data is 0.30599631468486166\n",
            "Similarity between Data Science Project and R is 0.16148293902501978\n",
            "Similarity between Data Science Project and chatbot is 0.16918044119791686\n",
            "Similarity between Data Science Project and time series is 0.23075522054413264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def compute_similarity(skill1, skill2):\n",
        "    skill1_vec = nlp(skill1).vector\n",
        "    skill2_vec = nlp(skill2).vector\n",
        "    similarity = 1 - (sum((skill1_vec - skill2_vec)**2) ** 0.5) / len(skill1_vec)\n",
        "    return similarity\n"
      ],
      "metadata": {
        "id": "zbNPj-726Rk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Define a function to calculate the Pearson correlation coefficient between two strings\n",
        "def pearson_sim(s1, s2):\n",
        "    s1 = s1.ljust(len(s2))\n",
        "    s2 = s2.ljust(len(s1))\n",
        "    s1 = [ord(c) for c in s1]\n",
        "    s2 = [ord(c) for c in s2]\n",
        "    return pearsonr(s1, s2)[0]\n"
      ],
      "metadata": {
        "id": "2ohsgHel7_mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def euclidean_distance(str1, str2):\n",
        "    \"\"\"\n",
        "    Calculates the Euclidean distance between the bag-of-words representations of two strings.\n",
        "\n",
        "    Args:\n",
        "        str1 (str): The first string.\n",
        "        str2 (str): The second string.\n",
        "\n",
        "    Returns:\n",
        "        float: The Euclidean distance between the two bag-of-words representations.\n",
        "    \"\"\"\n",
        "    # Create the bag-of-words representations\n",
        "    words1 = set(str1.split())\n",
        "    words2 = set(str2.split())\n",
        "    bag1 = [1 if w in words1 else 0 for w in set(words1).union(words2)]\n",
        "    bag2 = [1 if w in words2 else 0 for w in set(words1).union(words2)]\n",
        "    \n",
        "    # Calculate the Euclidean distance\n",
        "    squared_diffs = [(bag1[i] - bag2[i])**2 for i in range(len(bag1))]\n",
        "    return math.sqrt(sum(squared_diffs))\n"
      ],
      "metadata": {
        "id": "_MQx6Aa8hdyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "def compute_similarity(elem1, elem2):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    # fit_transform on list of strings\n",
        "    tfidf_list = tfidf_vectorizer.fit_transform([elem1, elem2])\n",
        "    similarities = cosine_similarity(tfidf_list)\n",
        "    similarity = similarities[0][1]\n",
        "    return similarity\n",
        "\n",
        "def jaccard_similarity(str1, str2):\n",
        "\n",
        "    set1 = set(str1.split())\n",
        "    set2 = set(str2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "# example usage\n",
        "list1 = list_specialite\n",
        "list2 = listaa\n",
        "for i in list1 :\n",
        "  for j in listq :\n",
        "    for k in j :\n",
        "      similarity = fast(i,k)\n",
        "      print(f\"Similarity between {i} and {k} is {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZa3XkbvzJAu",
        "outputId": "a87c6756-6174-439e-fa27-4061ef01e136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between Probability and web scraping is 0.1154286190867424\n",
            "Similarity between Probability and data analysis is 0.1154286190867424\n",
            "Similarity between Probability and Computer vision is 0.1154286190867424\n",
            "Similarity between Probability and Statistics is 0.1154286190867424\n",
            "Similarity between Probability and linear algebra is 0.1154286190867424\n",
            "Similarity between Probability and probability is 0.1154286190867424\n",
            "Similarity between Probability and machine learning is 0.1154286190867424\n",
            "Similarity between Probability and Natural language processing (NLP) is 0.1154286190867424\n",
            "Similarity between Probability and Deep learning language model is 0.1154286190867424\n",
            "Similarity between Probability and python is 0.1154286190867424\n",
            "Similarity between Probability and matlab is 0.1154286190867424\n",
            "Similarity between Probability and deep learning is 0.1154286190867424\n",
            "Similarity between Probability and data visualization is 0.1154286190867424\n",
            "Similarity between Probability and flask is 0.1154286190867424\n",
            "Similarity between Probability and django is 0.1154286190867424\n",
            "Similarity between Probability and big data is 0.1154286190867424\n",
            "Similarity between Probability and data integration is 0.1154286190867424\n",
            "Similarity between Probability and R is 0.1154286190867424\n",
            "Similarity between Probability and chatbot is 0.1154286190867424\n",
            "Similarity between Probability and time series is 0.1154286190867424\n",
            "Similarity between Probability and artificial intelligence is 0.1154286190867424\n",
            "Similarity between Statistics and web scraping is 0.16966164112091064\n",
            "Similarity between Statistics and data analysis is 0.16966164112091064\n",
            "Similarity between Statistics and Computer vision is 0.16966164112091064\n",
            "Similarity between Statistics and Statistics is 0.16966164112091064\n",
            "Similarity between Statistics and linear algebra is 0.16966164112091064\n",
            "Similarity between Statistics and probability is 0.16966164112091064\n",
            "Similarity between Statistics and machine learning is 0.16966164112091064\n",
            "Similarity between Statistics and Natural language processing (NLP) is 0.16966164112091064\n",
            "Similarity between Statistics and Deep learning language model is 0.16966164112091064\n",
            "Similarity between Statistics and python is 0.16966164112091064\n",
            "Similarity between Statistics and matlab is 0.16966164112091064\n",
            "Similarity between Statistics and deep learning is 0.16966164112091064\n",
            "Similarity between Statistics and data visualization is 0.16966164112091064\n",
            "Similarity between Statistics and flask is 0.16966164112091064\n",
            "Similarity between Statistics and django is 0.16966164112091064\n",
            "Similarity between Statistics and big data is 0.16966164112091064\n",
            "Similarity between Statistics and data integration is 0.16966164112091064\n",
            "Similarity between Statistics and R is 0.16966164112091064\n",
            "Similarity between Statistics and chatbot is 0.16966164112091064\n",
            "Similarity between Statistics and time series is 0.16966164112091064\n",
            "Similarity between Statistics and artificial intelligence is 0.16966164112091064\n",
            "Similarity between Machine Learning and web scraping is 0.18870434165000916\n",
            "Similarity between Machine Learning and data analysis is 0.18870434165000916\n",
            "Similarity between Machine Learning and Computer vision is 0.18870434165000916\n",
            "Similarity between Machine Learning and Statistics is 0.18870434165000916\n",
            "Similarity between Machine Learning and linear algebra is 0.18870434165000916\n",
            "Similarity between Machine Learning and probability is 0.18870434165000916\n",
            "Similarity between Machine Learning and machine learning is 0.18870434165000916\n",
            "Similarity between Machine Learning and Natural language processing (NLP) is 0.18870434165000916\n",
            "Similarity between Machine Learning and Deep learning language model is 0.18870434165000916\n",
            "Similarity between Machine Learning and python is 0.18870434165000916\n",
            "Similarity between Machine Learning and matlab is 0.18870434165000916\n",
            "Similarity between Machine Learning and deep learning is 0.18870434165000916\n",
            "Similarity between Machine Learning and data visualization is 0.18870434165000916\n",
            "Similarity between Machine Learning and flask is 0.18870434165000916\n",
            "Similarity between Machine Learning and django is 0.18870434165000916\n",
            "Similarity between Machine Learning and big data is 0.18870434165000916\n",
            "Similarity between Machine Learning and data integration is 0.18870434165000916\n",
            "Similarity between Machine Learning and R is 0.18870434165000916\n",
            "Similarity between Machine Learning and chatbot is 0.18870434165000916\n",
            "Similarity between Machine Learning and time series is 0.18870434165000916\n",
            "Similarity between Machine Learning and artificial intelligence is 0.18870434165000916\n",
            "Similarity between Big Data Analytics and web scraping is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and data analysis is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and Computer vision is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and Statistics is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and linear algebra is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and probability is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and machine learning is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and Natural language processing (NLP) is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and Deep learning language model is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and python is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and matlab is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and deep learning is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and data visualization is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and flask is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and django is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and big data is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and data integration is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and R is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and chatbot is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and time series is 0.46981945633888245\n",
            "Similarity between Big Data Analytics and artificial intelligence is 0.46981945633888245\n",
            "Similarity between Times Series  and web scraping is 0.2515214681625366\n",
            "Similarity between Times Series  and data analysis is 0.2515214681625366\n",
            "Similarity between Times Series  and Computer vision is 0.2515214681625366\n",
            "Similarity between Times Series  and Statistics is 0.2515214681625366\n",
            "Similarity between Times Series  and linear algebra is 0.2515214681625366\n",
            "Similarity between Times Series  and probability is 0.2515214681625366\n",
            "Similarity between Times Series  and machine learning is 0.2515214681625366\n",
            "Similarity between Times Series  and Natural language processing (NLP) is 0.2515214681625366\n",
            "Similarity between Times Series  and Deep learning language model is 0.2515214681625366\n",
            "Similarity between Times Series  and python is 0.2515214681625366\n",
            "Similarity between Times Series  and matlab is 0.2515214681625366\n",
            "Similarity between Times Series  and deep learning is 0.2515214681625366\n",
            "Similarity between Times Series  and data visualization is 0.2515214681625366\n",
            "Similarity between Times Series  and flask is 0.2515214681625366\n",
            "Similarity between Times Series  and django is 0.2515214681625366\n",
            "Similarity between Times Series  and big data is 0.2515214681625366\n",
            "Similarity between Times Series  and data integration is 0.2515214681625366\n",
            "Similarity between Times Series  and R is 0.2515214681625366\n",
            "Similarity between Times Series  and chatbot is 0.2515214681625366\n",
            "Similarity between Times Series  and time series is 0.2515214681625366\n",
            "Similarity between Times Series  and artificial intelligence is 0.2515214681625366\n",
            "Similarity between Python Framework for the Web and web scraping is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and data analysis is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and Computer vision is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and Statistics is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and linear algebra is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and probability is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and machine learning is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and Natural language processing (NLP) is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and Deep learning language model is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and python is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and matlab is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and deep learning is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and data visualization is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and flask is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and django is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and big data is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and data integration is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and R is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and chatbot is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and time series is 0.39000535011291504\n",
            "Similarity between Python Framework for the Web and artificial intelligence is 0.39000535011291504\n",
            "Similarity between Deep Learning and web scraping is 0.37817254662513733\n",
            "Similarity between Deep Learning and data analysis is 0.37817254662513733\n",
            "Similarity between Deep Learning and Computer vision is 0.37817254662513733\n",
            "Similarity between Deep Learning and Statistics is 0.37817254662513733\n",
            "Similarity between Deep Learning and linear algebra is 0.37817254662513733\n",
            "Similarity between Deep Learning and probability is 0.37817254662513733\n",
            "Similarity between Deep Learning and machine learning is 0.37817254662513733\n",
            "Similarity between Deep Learning and Natural language processing (NLP) is 0.37817254662513733\n",
            "Similarity between Deep Learning and Deep learning language model is 0.37817254662513733\n",
            "Similarity between Deep Learning and python is 0.37817254662513733\n",
            "Similarity between Deep Learning and matlab is 0.37817254662513733\n",
            "Similarity between Deep Learning and deep learning is 0.37817254662513733\n",
            "Similarity between Deep Learning and data visualization is 0.37817254662513733\n",
            "Similarity between Deep Learning and flask is 0.37817254662513733\n",
            "Similarity between Deep Learning and django is 0.37817254662513733\n",
            "Similarity between Deep Learning and big data is 0.37817254662513733\n",
            "Similarity between Deep Learning and data integration is 0.37817254662513733\n",
            "Similarity between Deep Learning and R is 0.37817254662513733\n",
            "Similarity between Deep Learning and chatbot is 0.37817254662513733\n",
            "Similarity between Deep Learning and time series is 0.37817254662513733\n",
            "Similarity between Deep Learning and artificial intelligence is 0.37817254662513733\n",
            "Similarity between Data Science Project and web scraping is 0.443257600069046\n",
            "Similarity between Data Science Project and data analysis is 0.443257600069046\n",
            "Similarity between Data Science Project and Computer vision is 0.443257600069046\n",
            "Similarity between Data Science Project and Statistics is 0.443257600069046\n",
            "Similarity between Data Science Project and linear algebra is 0.443257600069046\n",
            "Similarity between Data Science Project and probability is 0.443257600069046\n",
            "Similarity between Data Science Project and machine learning is 0.443257600069046\n",
            "Similarity between Data Science Project and Natural language processing (NLP) is 0.443257600069046\n",
            "Similarity between Data Science Project and Deep learning language model is 0.443257600069046\n",
            "Similarity between Data Science Project and python is 0.443257600069046\n",
            "Similarity between Data Science Project and matlab is 0.443257600069046\n",
            "Similarity between Data Science Project and deep learning is 0.443257600069046\n",
            "Similarity between Data Science Project and data visualization is 0.443257600069046\n",
            "Similarity between Data Science Project and flask is 0.443257600069046\n",
            "Similarity between Data Science Project and django is 0.443257600069046\n",
            "Similarity between Data Science Project and big data is 0.443257600069046\n",
            "Similarity between Data Science Project and data integration is 0.443257600069046\n",
            "Similarity between Data Science Project and R is 0.443257600069046\n",
            "Similarity between Data Science Project and chatbot is 0.443257600069046\n",
            "Similarity between Data Science Project and time series is 0.443257600069046\n",
            "Similarity between Data Science Project and artificial intelligence is 0.443257600069046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "03efFoU9_wub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJw3ViEmr5Rz",
        "outputId": "e1bdf35f-5f2f-4820-ba03-2351891b674c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZQo1e_dCu6_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "0auXdGz27HDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82325052-71b8-443d-d860-60157e9f8dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_commun = data_competances[data_competances.Topic==-1].Competency\t"
      ],
      "metadata": {
        "id": "zIhCGQE92_21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_commun "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCqRW2ZE3ayh",
        "outputId": "258bc10c-9ecf-46a6-8d65-504982fd1ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ['big data', 'shell scripting', 'project engin...\n",
              "Name: Competency, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Users Applicant vector\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "applicant_vector = tf.fit_transform((listaa)) #Users  Score\n",
        "jobS_record_vector = tf.transform(list_specialite)\n",
        "candidate_cos_similarity = map(lambda x: cosine_similarity(jobS_record_vector, x),applicant_vector)\n",
        "\n",
        "candidate_score = list(candidate_cos_similarity)\n",
        "top_candidates = sorted(range(len(candidate_score)), key=lambda i: candidate_score[i], reverse=True)[:5]\n",
        "list_scores = [candidate_score[i][0][0] for i in top_candidates]\n"
      ],
      "metadata": {
        "id": "k5p8Rlg4KPgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppEo2rKjdt-k",
        "outputId": "62e8f18c-9a8b-4d3b-df29-3349fe395e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdAvYpTOIU1_",
        "outputId": "a3d0c40f-1f35-49f7-e7af-a09bf7a89735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsZgXbvGNXav",
        "outputId": "a64475ec-93f1-4183-b713-128836c5b7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Add a dense layer for binary classification\n",
        "classifier_layer = torch.nn.Linear(768, 1)\n",
        "model.classifier = classifier_layer\n",
        "\n",
        "# Define the input sentences\n",
        "sentences1 = [\"Data science\"]\n",
        "sentences2 = [\"lkjnk\"]\n",
        "\n",
        "# Tokenize the input sentences with BERT tokenizer\n",
        "max_seq_length = 128\n",
        "input_ids1 = []\n",
        "attention_masks1 = []\n",
        "for sent in sentences1:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_seq_length,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "    input_ids1.append(encoded_dict['input_ids'])\n",
        "    attention_masks1.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids2 = []\n",
        "attention_masks2 = []\n",
        "for sent in sentences2:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_seq_length,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "    input_ids2.append(encoded_dict['input_ids'])\n",
        "    attention_masks2.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert input IDs and attention masks to tensors\n",
        "input_ids1 = torch.cat(input_ids1, dim=0)\n",
        "attention_masks1 = torch.cat(attention_masks1, dim=0)\n",
        "input_ids2 = torch.cat(input_ids2, dim=0)\n",
        "attention_masks2 = torch.cat(attention_masks2, dim=0)\n",
        "\n",
        "# Get BERT embeddings for input sentences\n",
        "with torch.no_grad():\n",
        "    embeddings1 = model(input_ids1, attention_mask=attention_masks1)[0][:,0,:].numpy()\n",
        "    embeddings2 = model(input_ids2, attention_mask=attention_masks2)[0][:,0,:].numpy()\n",
        "\n",
        "# Calculate cosine similarity between sentence embeddings\n",
        "similarity_scores = cosine_similarity(embeddings1, embeddings2)\n",
        "\n",
        "# Print the similarity scores\n",
        "print(\"Similarity scores for sentences1 and sentences2:\")\n",
        "for i in range(len(sentences1)):\n",
        "    for j in range(len(sentences2)):\n",
        "        similarity_score = similarity_scores[i][j]\n",
        "        print(f\"{sentences1[i]} VS {sentences2[j]}: {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJnYE8bQI6CI",
        "outputId": "367d112c-a92e-4a8a-d7e3-9cb6f6496a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity scores for sentences1 and sentences2:\n",
            "Data science VS lkjnk: 0.8627094030380249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow tensorflow-hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Voo_5aqL4Drh",
        "outputId": "97f75710-5c3f-4cd7-91cd-6369f47be57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBuBuj4PxD6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzywuzzy\n"
      ],
      "metadata": {
        "id": "RE2j1KDTxf5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eeae105-c3ed-4d80-efbb-262ac3b3bfbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC6rjaj_lL0p",
        "outputId": "8525a02a-8b38-4cda-fee1-cc17172a2394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.partial_ratio(\"Python\", \"Statistics\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcOgtz5JlUhE",
        "outputId": "c4a8b490-c192-4ce5-b418-f55d3a30003e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.ratio(\"this is a test\", \"this is a test!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWNF9Dphlgln",
        "outputId": "2590d9ca-7ad9-45b3-b476-a5792ff23786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(\"Node JS\", \"Web\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-OSCP9UmDkg",
        "outputId": "de1a21e4-ae27-4ac3-c0f5-f69b8659bc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}